{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_ranger(n,a,b):\n",
    "    valid=[]\n",
    "    i=0\n",
    "    while i**n <= b:\n",
    "        if i**n >= a and i**n <= b:\n",
    "            valid.append(i**n)\n",
    "        i+=1\n",
    "    return len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_ranger(4, 250, 1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from keras.models import load_model\n",
    "import random\n",
    "\n",
    "model_path = \"model\\\\3DCNN+3LSTM_128_4_aug_v4.h5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img_rows,img_cols=128, 128\n",
    "framecount = 0\n",
    "fps = \"\"\n",
    "start = time.time()\n",
    "frames = []\n",
    "confidence =''\n",
    "pred=''\n",
    "classes = ['Jap','Hook','Uppercut','None']\n",
    "\n",
    "previous = 0\n",
    "score =0\n",
    "pose = 3\n",
    "hit = False\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('Original', cv2.WINDOW_NORMAL)\n",
    "# set rt size as 640x480\n",
    "ret = cap.set(3,640)\n",
    "ret = cap.set(4,480)\n",
    "time.sleep(2)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    time.sleep(0.1)\n",
    "    frame = cv2.flip(frame, 3)\n",
    "    \n",
    "    framecount = framecount + 1\n",
    "    end  = time.time()\n",
    "    timediff = (end - start)\n",
    "    if( timediff >= 1):\n",
    "        fps = 'FPS:%s' %(framecount)\n",
    "        start = time.time()\n",
    "        framecount = 0\n",
    "    cv2.putText(frame,fps,(10,20), font, 0.7,(0,255,0),2,1)\n",
    "    \n",
    "    image=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    frames.append(rgb)\n",
    "    input=np.array(frames)\n",
    "    \n",
    "    if len(input)==10: # initiate instruction\n",
    "        pose = random.randint(0,2)\n",
    "        if previous == pose: # ensure different psoe is generated\n",
    "            pose +=1\n",
    "        if pose ==3:\n",
    "            pose =0\n",
    "        count =0\n",
    "        hit = False\n",
    "        \n",
    "    if len(input)==24: # prediction\n",
    "        frames = []\n",
    "        X_train = np.expand_dims(input, axis=0)\n",
    "        train_set = X_train.astype('float16')\n",
    "        train_set -= 111.75\n",
    "        train_set /= 143.2\n",
    "        result = model.predict(train_set)\n",
    "        num = np.argmax(result,axis =1)\n",
    "        max = np.max(result,axis = 1)\n",
    "        confidence = max[0]\n",
    "        pred = str(classes[int(num[0])])\n",
    "        input=[]    \n",
    "        \n",
    "        if pose==num:\n",
    "            hit = True\n",
    "            if confidence >= 0.8:\n",
    "                score +=100\n",
    "            elif confidence >= 0.4 and confidence < 0.8:\n",
    "                score +=80\n",
    "            else:\n",
    "                score +=50\n",
    "                \n",
    "        print('pose: '+str(pose))\n",
    "        print('pred: '+str(num))\n",
    "        print('confidence: '+str(confidence))\n",
    "        print(hit)\n",
    "    \n",
    "    if len(input) <10:  # show if hit\n",
    "        if hit:\n",
    "            if confidence >= 0.8:\n",
    "                cv2.putText(frame, 'PERFECT!', (280,250), font, 2, (255, 255, 255), 4, 8)\n",
    "            elif confidence >= 0.4 and confidence < 0.8:\n",
    "                cv2.putText(frame, 'GOOD!', (280,250), font, 2, (255, 255, 255), 4, 8)\n",
    "            else:\n",
    "                cv2.putText(frame, 'HIT!', (280,250), font, 2, (255, 255, 255), 4, 8)\n",
    "        else:\n",
    "            cv2.putText(frame, 'MISS!', (280,250), font, 2, (0, 0, 255), 4, 8)\n",
    "       \n",
    "    # layout\n",
    "    cv2.putText(frame, classes[pose] , (300,400), font, 2, (255, 255, 0), 2, 3)\n",
    "    cv2.putText(frame, 'Score: ' + str(score), (580,20), font, 0.7, (0, 255, 0), 2, 1)\n",
    "    cv2.putText(frame, 'Confidence: ' + str(confidence), (10, 100), font, 0.7, (0, 255, 0), 2, 1)\n",
    "    cv2.putText(frame, 'Class: ' + pred, (10, 50), font, 0.7, (0, 255, 0), 2, 1)\n",
    "    cv2.imshow('Original',frame)\n",
    "    \n",
    "    previous = pose\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "import threading\n",
    "\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = 'models/' + MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "CWD_PATH = os.getcwd()\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH,'object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "print(PATH_TO_LABELS)\n",
    "NUM_CLASSES = 90\n",
    "IMAGE_WIDTH = 640\n",
    "IMAGE_HEIGHT = 480\n",
    "\n",
    "class OutputFrame:\n",
    "    def __init__(self):\n",
    "        self.frame = np.zeros((IMAGE_HEIGHT,IMAGE_WIDTH,3))\n",
    "        self.boxes = ()\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "class WebcamThread(threading.Thread):\n",
    "   def __init__(self, name):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.name = name\n",
    "   def run(self):\n",
    "      print(\"Starting \" + self.name)\n",
    "      get_frame(self.name)\n",
    "      print(\"Exiting \" + self.name)\n",
    "\n",
    "def get_frame(threadName):\n",
    "    while not done:\n",
    "        _, frame = cap.read()\n",
    "        output_frame.frame = frame\n",
    "\n",
    "class PredictorThread(threading.Thread):\n",
    "   def __init__(self, name):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.name = name\n",
    "   def run(self):\n",
    "      print(\"Starting \" + self.name)\n",
    "      predict(self.name)\n",
    "      print(\"Exiting \" + self.name)\n",
    "\n",
    "def predict(threadName):\n",
    "    while not done:\n",
    "        _, image_np = cap.read()\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        # Actual detection.\n",
    "        output_frame.boxes = sess.run(\n",
    "          [boxes, scores, classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    done = False\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    fourcc = cv2.VideoWriter_fourcc('a', 'v', 'c', '1') # note the lower case\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480), True)\n",
    "    cap.set(3, IMAGE_WIDTH)\n",
    "    cap.set(4, IMAGE_HEIGHT)\n",
    "    sess = tf.Session(graph=detection_graph)\n",
    "    output_frame = OutputFrame()\n",
    "\n",
    "    webcam_thread = WebcamThread(\"Webcam Thread\")\n",
    "    predictor_thread = PredictorThread(\"Predictor Thread\")\n",
    "    webcam_thread.start()\n",
    "    predictor_thread.start()\n",
    "\n",
    "    while True:\n",
    "        if output_frame.boxes == ():\n",
    "            to_show = output_frame.frame\n",
    "        else:\n",
    "            to_show = output_frame.frame\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              to_show,\n",
    "              np.squeeze(output_frame.boxes[0]),\n",
    "              np.squeeze(output_frame.boxes[2]).astype(np.int32),\n",
    "              np.squeeze(output_frame.boxes[1]),\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=8)\n",
    "\n",
    "        cv2.imshow('frame', to_show)\n",
    "        out.write((to_show).astype('u1'))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from collections import deque\n",
    "import threading\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# img_rows,img_cols=128, 128\n",
    "label = 'Warming Up...'\n",
    "classes = ['Jap','Hook','Uppercut','None']\n",
    "frames = deque(maxlen=24)\n",
    "framecount = 0\n",
    "# pose = 'Ready'\n",
    "\n",
    "class PredictorThread(threading.Thread):\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        global label,frames\n",
    "        print(\"[INFO] loading network...\")\n",
    "        model_path = \"model\\\\3DCNN+3LSTM_128_4_aug_v4.h5\"\n",
    "        self.model = load_model(model_path)\n",
    "        print(\"[INFO] model loaded successfully...\")\n",
    "\n",
    "        while (~(frame is None)):\n",
    "#             rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            print(len(frames))\n",
    "#             cv2.putText(original, str(len(frames)), (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            if len(frames) < 24:\n",
    "                continue\n",
    "            else:\n",
    "                np_frames = np.array(frames)\n",
    "                label, confidence = self.predict(np_frames)\n",
    "                for i in range(12):\n",
    "                    frames.popleft()\n",
    "                print(label)\n",
    "            \n",
    "    def predict(self, frames):\n",
    "        X_train = np.expand_dims(frames, axis=0)\n",
    "#         print(X_train.shape)\n",
    "        train_set = X_train.astype('float16')\n",
    "        train_set -= 111.75\n",
    "        train_set /= 143.2\n",
    "        preds = self.model.predict(train_set)\n",
    "        print(preds)\n",
    "        label = classes[np.argmax(preds,axis=1)[0]]\n",
    "        confidence = np.max(preds,axis=1)[0]\n",
    "        return label, confidence\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cv2.namedWindow('Original', cv2.WINDOW_NORMAL)\n",
    "ret = cap.set(3,640)\n",
    "ret = cap.set(4,480)\n",
    "time.sleep(5)\n",
    "\n",
    "keras_thread = PredictorThread()\n",
    "keras_thread.start()\n",
    "\n",
    "while True:\n",
    "    ret, original = cap.read()\n",
    "    original = cv2.flip(original, 3)\n",
    "    frame = cv2.resize(original,(128,128),interpolation=cv2.INTER_AREA)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    framecount = framecount + 1\n",
    "    print('framecount = '+str(framecount))\n",
    "    # Display the predictions\n",
    "#     cv2.putText(original, str(frameno), (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.putText(original, \"Label: {}\".format(label), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Classification\", original)\n",
    "\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break;\n",
    "\n",
    "cap.release()\n",
    "frame = None\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from imagenet_utils import decode_predictions\n",
    "from imagenet_utils import preprocess_input\n",
    "from vgg16 import VGG16\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import threading\n",
    "\n",
    "label = ''\n",
    "frame = None\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    def __init__(self):\n",
    "        threading.Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        global label\n",
    "        # Load the VGG16 network\n",
    "        print(\"[INFO] loading network...\")\n",
    "        self.model = VGG16(weights=\"imagenet\")\n",
    "\n",
    "        while (~(frame is None)):\n",
    "            (inID, label) = self.predict(3)\n",
    "\n",
    "    def predict(self, frame):\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((1,) + image.shape)\n",
    "\n",
    "        image = preprocess_input(image)\n",
    "        preds = self.model.predict(image)\n",
    "        return decode_predictions(preds)[0]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if (cap.isOpened()):\n",
    "    print(\"Camera OK\")\n",
    "else:\n",
    "    cap.open()\n",
    "\n",
    "keras_thread = MyThread()\n",
    "keras_thread.start()\n",
    "\n",
    "while (True):\n",
    "    ret, original = cap.read()\n",
    "\n",
    "    frame = cv2.resize(original, (224, 224))\n",
    "\n",
    "    # Display the predictions\n",
    "    # print(\"ImageNet ID: {}, Label: {}\".format(inID, label))\n",
    "    cv2.putText(original, \"Label: {}\".format(label), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Classification\", original)\n",
    "\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break;\n",
    "\n",
    "cap.release()\n",
    "frame = None\n",
    "cv2.destroyAllWindows()\n",
    "sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
